{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = ChatOpenAI()\n",
    "\n",
    "# chat.predict(\"How many planets are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hola, mi nombre es Miguel. La distancia entre México y Tailandia es de aproximadamente 16,000 kilómetros.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content = \"You are a geography expert. And you only reply in Spanish\",),\n",
    "    AIMessage(content= \"Hola, mi nombre es Miguel\"),\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand. Also, what is your name\")\n",
    "\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Korea and Japan is approximately 900 kilometers (560 miles) across the Korea Strait.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate.from_template(\"what is the distance between {country_a} and  {country_b},\")\n",
    "\n",
    "prompt = template.format(country_a=\"Korea\", country_b=\"Japan\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='韓国と日本の間の距離は約約200kmです。私の名前はセツです。どうぞよろしくお願いします。')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "        (\"ai\", \"こんにちは、私の名前は{name}です\"),\n",
    "        (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    language =\"Japanese\",\n",
    "    name =\"セツ\",\n",
    "    country_a = \"Korea\",\n",
    "    country_b = \"Japan\"\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 OutputParser and LCEL "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items =text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "p = CommaOutputParser()\n",
    "p.parse(\"Hello, how, are, you\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rose',\n",
       " 'sunflower',\n",
       " 'fern',\n",
       " 'cactus',\n",
       " 'tulip',\n",
       " 'daisy',\n",
       " 'orchid',\n",
       " 'lavender',\n",
       " 'succulent',\n",
       " 'daffodil']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked\\\n",
    "        will be answered with a comma seperated list of max {max_items} in lowercase.\\\n",
    "        Do NOT reply with anything else.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items =10,\n",
    "    question = \"What are the plants?\"\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        items =text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a list generating machine. Everything you are asked\\\n",
    "        will be answered with a comma seperated list of max {max_items} in lowercase.\\\n",
    "        Do NOT reply with anything else.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bulbasaur',\n",
       " 'ivysaur',\n",
       " 'venusaur',\n",
       " 'charmander',\n",
       " 'charmeleon',\n",
       " 'charizard',\n",
       " 'squirtle',\n",
       " 'wartortle',\n",
       " 'blastoise',\n",
       " 'pikachu']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke(\n",
    "   {\"max_items\": 10,\n",
    "    \"question\" : \"What are the pokemons?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Chaining Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(temperature=0.1,\n",
    "                  streaming=True, # showing what is going on during the process\n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a world-class international chef. \\\n",
    "         You create easy to follow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a vegetarian chef specialized on making traditional recipes vegetarian. \\\n",
    "         You find alternative ingredients and explain their preparation. \\\n",
    "         You don't radically modify the recipe. \\\n",
    "         If there is no alternative for a food just say you don't know how to recipe it.\"), \n",
    "        (\"human\", \"{recipe}\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! How about making some delicious Bibimbap? Here's a simple recipe for you to try at home:\n",
      "\n",
      "Ingredients:\n",
      "- 2 cups cooked white rice\n",
      "- 1 carrot, julienned\n",
      "- 1 zucchini, julienned\n",
      "- 1 cup spinach\n",
      "- 1 cup bean sprouts\n",
      "- 4 shiitake mushrooms, sliced\n",
      "- 1/2 pound beef (you can use ribeye or sirloin), thinly sliced\n",
      "- 4 eggs\n",
      "- 4 tablespoons soy sauce\n",
      "- 2 tablespoons sesame oil\n",
      "- 2 tablespoons gochujang (Korean red chili paste)\n",
      "- 2 cloves garlic, minced\n",
      "- Salt and pepper to taste\n",
      "- Sesame seeds for garnish\n",
      "- Vegetable oil for cooking\n",
      "\n",
      "Instructions:\n",
      "1. Marinate the beef: In a bowl, mix the beef with 2 tablespoons of soy sauce, 1 tablespoon of sesame oil, minced garlic, salt, and pepper. Let it marinate for at least 30 minutes.\n",
      "2. Prepare the vegetables: Blanch the spinach in boiling water for 1 minute, then rinse with cold water and squeeze out excess water. Season with a pinch of salt and a drizzle of sesame oil. Blanch the bean sprouts in boiling water for 2 minutes, then rinse with cold water and squeeze out excess water. Season with a pinch of salt and a drizzle of sesame oil. Sauté the carrots, zucchini, and mushrooms separately in a pan with a little vegetable oil until tender. Season with salt and pepper.\n",
      "3. Cook the beef: In a hot pan, cook the marinated beef until browned and cooked through. Set aside.\n",
      "4. Fry the eggs: In the same pan, fry the eggs sunny side up or over easy.\n",
      "5. Assemble the Bibimbap: Divide the cooked rice into bowls. Arrange the cooked vegetables, beef, and fried eggs on top of the rice.\n",
      "6. Make the Bibimbap sauce: In a small bowl, mix 2 tablespoons of gochujang, 2 tablespoons of soy sauce, and 1 tablespoon of sesame oil. Adjust the seasoning to taste.\n",
      "7. Serve the Bibimbap: Drizzle the Bibimbap sauce over the ingredients in the bowl. Sprinkle with sesame seeds and serve hot.\n",
      "\n",
      "Enjoy your homemade Bibimbap! Feel free to customize the toppings to your liking. Let me know if you have any questions or need more Korean recipe ideas.To make this Bibimbap recipe vegetarian, you can make a few simple swaps:\n",
      "\n",
      "- Instead of beef, you can use tofu as a protein alternative. Extra-firm tofu works well for this dish. Cut the tofu into thin slices or cubes and marinate it in a mixture of soy sauce, sesame oil, minced garlic, salt, and pepper for at least 30 minutes before cooking.\n",
      "\n",
      "- For the eggs, you can omit them or use a plant-based egg alternative if desired.\n",
      "\n",
      "- To replace the meaty flavor of shiitake mushrooms, you can use a mix of other mushrooms like cremini or portobello mushrooms. Slice them and sauté them until tender.\n",
      "\n",
      "- If you prefer a vegan version, you can skip the eggs and adjust the Bibimbap sauce by using a vegan-friendly gochujang paste and ensuring the soy sauce you use is also vegan.\n",
      "\n",
      "By making these ingredient swaps, you can enjoy a delicious vegetarian Bibimbap that stays true to the traditional flavors of the dish. Enjoy your homemade vegetarian Bibimbap!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='To make this Bibimbap recipe vegetarian, you can make a few simple swaps:\\n\\n- Instead of beef, you can use tofu as a protein alternative. Extra-firm tofu works well for this dish. Cut the tofu into thin slices or cubes and marinate it in a mixture of soy sauce, sesame oil, minced garlic, salt, and pepper for at least 30 minutes before cooking.\\n\\n- For the eggs, you can omit them or use a plant-based egg alternative if desired.\\n\\n- To replace the meaty flavor of shiitake mushrooms, you can use a mix of other mushrooms like cremini or portobello mushrooms. Slice them and sauté them until tender.\\n\\n- If you prefer a vegan version, you can skip the eggs and adjust the Bibimbap sauce by using a vegan-friendly gochujang paste and ensuring the soy sauce you use is also vegan.\\n\\nBy making these ingredient swaps, you can enjoy a delicious vegetarian Bibimbap that stays true to the traditional flavors of the dish. Enjoy your homemade vegetarian Bibimbap!')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chef_chain = chef_prompt | chat\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\":chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke(\n",
    "    {\n",
    "        \"cuisine\": \"Korean\",\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
